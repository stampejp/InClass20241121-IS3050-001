{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stampejp/data-mining/blob/master/labs/10_wk10_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# Week 10 Lab: Logistic Regression and Classification Evaluation\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/bradleyboehmke/uc-bana-4080/blob/main/labs/10_wk10_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "Welcome to Week 10! This lab serves as both your Thursday class session and your homework for the week. You'll apply logistic regression and classification evaluation techniques to two important business scenarios: credit risk assessment and medical diagnosis support.\n",
        "\n",
        "In the business world, classification problems are everywhere—from determining loan approvals to medical screenings. Today you'll master the complete workflow from data preparation through model evaluation, learning to choose appropriate metrics that align with business objectives and costs.\n",
        "\n",
        "## 🎯 Learning Objectives\n",
        "By the end of this lab, you will be able to:\n",
        "- Apply the complete logistic regression workflow: data preparation, model fitting, and interpretation\n",
        "- Calculate and interpret baseline ratios for imbalanced classification problems\n",
        "- Evaluate classification models using precision, recall, F1-score, and ROC-AUC metrics\n",
        "- Select appropriate evaluation metrics based on business context and error costs\n",
        "\n",
        "## 📚 This Lab Reinforces\n",
        "- **Chapter 23: Introduction to Logistic Regression for Classification**\n",
        "- **Chapter 24: Evaluating Classification Models**\n",
        "- **Tuesday's Lecture: Classification Methods and Model Evaluation**\n",
        "\n",
        "## 🕐 Estimated Time & Structure\n",
        "**Total Time:** 75 minutes  \n",
        "**Mode:** Individual work (this serves as your homework)\n",
        "\n",
        "- **[0–10 min]** Review: Default dataset logistic regression workflow\n",
        "- **[10–35 min]** Application: Breast Cancer Wisconsin dataset analysis\n",
        "- **[35–70 min]** Independent challenges: Specific homework questions\n",
        "- **[70–75 min]** Wrap-up and submission preparation\n",
        "\n",
        "## 💡 Why This Matters\n",
        "Classification problems drive critical business decisions across industries. Credit companies need to assess default risk, healthcare systems require diagnostic support, and marketing teams must identify likely customers. The ability to build, evaluate, and interpret classification models—while understanding the business implications of different types of errors—is essential for data-driven decision making. Today's lab prepares you to tackle these real-world challenges with confidence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "## Setup\n",
        "We'll work with two datasets: the Default dataset from ISLP (for review) and the Breast Cancer Wisconsin dataset (for our main analysis). Both represent important classification scenarios in business and healthcare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cell-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-2",
        "outputId": "afc549b3-ba5c-4f9c-85b0-31c936dcd134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported successfully!\n",
            "🎯 Ready to dive into classification analysis!\n"
          ]
        }
      ],
      "source": [
        "# Required imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve\n",
        ")\n",
        "from ISLP import load_data\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random state for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "print(\"🎯 Ready to dive into classification analysis!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b767933"
      },
      "source": [
        "The error message `ModuleNotFoundError: No module named 'ISLP'` indicates that the `ISLP` library is not installed in your current Python environment. You can install it using `pip`."
      ],
      "id": "3b767933"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1495d0ec",
        "outputId": "d45e411c-6e22-4407-b32a-3e176d229360"
      },
      "source": [
        "%pip install ISLP"
      ],
      "id": "1495d0ec",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from ISLP) (5.4.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from ISLP) (1.5.2)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.12/dist-packages (from ISLP) (0.14.5)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.10.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from ISLP) (2.8.0+cu126)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->ISLP) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13->ISLP) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13->ISLP) (25.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines->ISLP) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: progressbar2<5,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->ISLP) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->ISLP) (3.4.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (2.0.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.5)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from progressbar2<5,>=4.2.0->pygam->ISLP) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->ISLP) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->ISLP) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.11)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.10.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=5e5dd9aa71db4bf19d8e12599245dc460be69324e3c776a005db239903365351\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: lightning-utilities, interface-meta, autograd-gamma, pygam, formulaic, torchmetrics, lifelines, pytorch-lightning, ISLP\n",
            "Successfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.15.2 pygam-0.10.1 pytorch-lightning-2.5.5 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "## Part 1 — Review: Default Dataset Logistic Regression (10 minutes)\n",
        "\n",
        "Let's quickly review the complete logistic regression workflow using the Default dataset from Chapters 23-24. This will reinforce the key concepts before we tackle the main dataset.\n",
        "\n",
        "### Quick Workflow Review\n",
        "\n",
        "We'll walk through each step systematically:\n",
        "\n",
        "**📋 Step-by-step process:**\n",
        "1. Load data and compute baseline ratio\n",
        "2. Prepare features with dummy encoding\n",
        "3. Split data into training and test sets\n",
        "4. Fit logistic regression model and interpret coefficients\n",
        "5. Make predictions and evaluate using multiple metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-4",
        "outputId": "46781620-90af-4a48-acc3-b55a13962262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Dataset Overview:\n",
            "Shape: (10000, 4)\n",
            "\n",
            "Columns: ['default', 'student', 'balance', 'income']\n",
            "\n",
            "First few rows:\n",
            "  default student      balance        income\n",
            "0      No      No   729.526495  44361.625074\n",
            "1      No     Yes   817.180407  12106.134700\n",
            "2      No      No  1073.549164  31767.138947\n",
            "3      No      No   529.250605  35704.493935\n",
            "4      No      No   785.655883  38463.495879\n",
            "\n",
            "📊 Baseline Analysis:\n",
            "Default rate: 3.3%\n",
            "Non-default rate: 96.7%\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Default dataset and examine baseline\n",
        "Default = load_data('Default')\n",
        "\n",
        "print(\"Default Dataset Overview:\")\n",
        "print(f\"Shape: {Default.shape}\")\n",
        "print(f\"\\nColumns: {Default.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(Default.head())\n",
        "\n",
        "# Compute baseline ratio\n",
        "baseline_default_rate = (Default['default'] == 'Yes').mean()\n",
        "print(f\"\\n📊 Baseline Analysis:\")\n",
        "print(f\"Default rate: {baseline_default_rate:.1%}\")\n",
        "print(f\"Non-default rate: {1-baseline_default_rate:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cell-5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-5",
        "outputId": "cc49e47d-c302-42b8-cd04-49fa039e616e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preparation Complete:\n",
            "Features shape: (10000, 3)\n",
            "Target shape: (10000,)\n",
            "\n",
            "Feature columns: ['balance', 'income', 'student_Yes']\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Prepare data with dummy encoding\n",
        "# Convert categorical variables to numeric\n",
        "Default_encoded = pd.get_dummies(Default, columns=['student'], drop_first=True)\n",
        "Default_encoded['default_binary'] = (Default_encoded['default'] == 'Yes').astype(int)\n",
        "\n",
        "# Define features and target\n",
        "X = Default_encoded[['balance', 'income', 'student_Yes']]\n",
        "y = Default_encoded['default_binary']\n",
        "\n",
        "print(\"Data Preparation Complete:\")\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeature columns: {X.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cell-6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-6",
        "outputId": "4c339ef4-cf5c-46ab-8a22-0f1debaf1dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Data Split Results:\n",
            "Training set: 7,000 observations\n",
            "Test set: 3,000 observations\n",
            "\n",
            "Training set default rate: 3.4%\n",
            "Test set default rate: 3.1%\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Split data (70-30 split as specified for homework questions)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"📊 Data Split Results:\")\n",
        "print(f\"Training set: {len(X_train):,} observations\")\n",
        "print(f\"Test set: {len(X_test):,} observations\")\n",
        "print(f\"\\nTraining set default rate: {y_train.mean():.1%}\")\n",
        "print(f\"Test set default rate: {y_test.mean():.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-7",
        "outputId": "59a108db-0094-49b0-e1bd-f60653e9b776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Model Coefficients:\n",
            "Intercept: -11.108164\n",
            "balance: 0.005789\n",
            "income: 0.000006\n",
            "student_Yes: -0.467459\n",
            "\n",
            "💡 Interpretation:\n",
            "• Balance: Positive coefficient means higher balance increases default risk\n",
            "• Income: Very small coefficient suggests minimal impact after accounting for balance\n",
            "• Student: Negative coefficient means students have lower default risk (holding other factors constant)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Fit logistic regression model\n",
        "model = LogisticRegression(random_state=RANDOM_STATE)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Extract and interpret coefficients\n",
        "print(\"🔍 Model Coefficients:\")\n",
        "print(f\"Intercept: {model.intercept_[0]:.6f}\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.6f}\")\n",
        "\n",
        "print(f\"\\n💡 Interpretation:\")\n",
        "print(f\"• Balance: Positive coefficient means higher balance increases default risk\")\n",
        "print(f\"• Income: Very small coefficient suggests minimal impact after accounting for balance\")\n",
        "print(f\"• Student: Negative coefficient means students have lower default risk (holding other factors constant)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cell-8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-8",
        "outputId": "094a9040-0fd4-462b-93ab-1300d00554f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Model Performance Metrics:\n",
            "Accuracy:  97.3%\n",
            "Precision: 69.4%\n",
            "Recall:    26.6%\n",
            "F1-Score:  38.5%\n",
            "ROC-AUC:   0.947\n",
            "\n",
            "💡 What These Metrics Mean for Credit Risk:\n",
            "• Accuracy (97.3%): Overall correctness - 97.3% of all predictions are correct\n",
            "• Precision (69.4%): Of customers flagged as 'will default', 69.4% actually do\n",
            "  → Low false alarms but still 30.6% false positives\n",
            "• Recall (26.6%): Only catches 26.6% of actual defaulters\n",
            "  → Misses 73.4% of customers who will default - major business risk!\n",
            "• F1-Score (38.5%): Balanced measure showing poor overall classification performance\n",
            "• ROC-AUC (0.947): Excellent ability to rank customers by default risk\n",
            "  → Model is very good at scoring, but default threshold may need adjustment\n",
            "\n",
            "🔍 Confusion Matrix:\n",
            "[[2895,  11]]\n",
            "[[  69,  25]]\n",
            "\n",
            "This shows: TN=2895, FP=11, FN=69, TP=25\n",
            "Business Impact: 69 defaulters missed (lost revenue), 11 customers wrongly rejected (lost business)\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Make predictions and evaluate comprehensively\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate all key metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"📈 Model Performance Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy:.1%}\")\n",
        "print(f\"Precision: {precision:.1%}\")\n",
        "print(f\"Recall:    {recall:.1%}\")\n",
        "print(f\"F1-Score:  {f1:.1%}\")\n",
        "print(f\"ROC-AUC:   {auc:.3f}\")\n",
        "\n",
        "print(f\"\\n💡 What These Metrics Mean for Credit Risk:\")\n",
        "print(f\"• Accuracy (97.3%): Overall correctness - 97.3% of all predictions are correct\")\n",
        "print(f\"• Precision (69.4%): Of customers flagged as 'will default', 69.4% actually do\")\n",
        "print(f\"  → Low false alarms but still 30.6% false positives\")\n",
        "print(f\"• Recall (26.6%): Only catches 26.6% of actual defaulters\")\n",
        "print(f\"  → Misses 73.4% of customers who will default - major business risk!\")\n",
        "print(f\"• F1-Score (38.5%): Balanced measure showing poor overall classification performance\")\n",
        "print(f\"• ROC-AUC (0.947): Excellent ability to rank customers by default risk\")\n",
        "print(f\"  → Model is very good at scoring, but default threshold may need adjustment\")\n",
        "\n",
        "# Show confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\n🔍 Confusion Matrix:\")\n",
        "print(f\"[[{cm[0,0]:4d}, {cm[0,1]:3d}]]\")\n",
        "print(f\"[[{cm[1,0]:4d}, {cm[1,1]:3d}]]\")\n",
        "print(f\"\\nThis shows: TN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}, TP={cm[1,1]}\")\n",
        "print(f\"Business Impact: {cm[1,0]} defaulters missed (lost revenue), {cm[0,1]} customers wrongly rejected (lost business)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {
        "id": "cell-9"
      },
      "source": [
        "## Part 2 — Main Analysis: Breast Cancer Wisconsin Dataset (25 minutes)\n",
        "\n",
        "Now let's apply these skills to a new healthcare dataset. The **Breast Cancer Wisconsin (Diagnostic) dataset** contains features computed from digitized images of fine needle aspirate (FNA) of breast masses. Our goal is to predict whether a tumor is **malignant** (cancerous) or **benign** (non-cancerous).\n",
        "\n",
        "### 🔬 About This Dataset\n",
        "\n",
        "**Data Source**: Originally created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin-Madison. This dataset is widely used in machine learning research and medical informatics.\n",
        "\n",
        "**Data Collection Process**: For each breast mass sample, a fine needle aspirate (FNA) was performed, then digitized images were analyzed to compute quantitative features describing the cell nuclei characteristics.\n",
        "\n",
        "### 📊 Feature Categories\n",
        "\n",
        "The dataset contains **30 quantitative features** organized into three groups for each characteristic:\n",
        "\n",
        "1. **Mean values** (`_mean`): Average across all cells in the sample\n",
        "2. **Standard error** (`_se`): Standard error of the measurements  \n",
        "3. **Worst values** (`_worst`): Mean of the three largest (most severe) values\n",
        "\n",
        "**The 10 core characteristics measured are:**\n",
        "\n",
        "- **`radius`**: Distance from center to perimeter points\n",
        "- **`texture`**: Standard deviation of gray-scale values  \n",
        "- **`perimeter`**: Total boundary length of the cell nucleus\n",
        "- **`area`**: Total area enclosed by the cell nucleus boundary\n",
        "- **`smoothness`**: Local variation in radius lengths\n",
        "- **`compactness`**: (perimeter² / area) - 1.0, measuring shape regularity\n",
        "- **`concavity`**: Severity of concave portions of the boundary\n",
        "- **`concave_points`**: Number of concave portions of the boundary\n",
        "- **`symmetry`**: Bilateral symmetry of the cell nucleus\n",
        "- **`fractal_dimension`**: Fractal complexity using coastline approximation\n",
        "\n",
        "### 🎯 Simplified Analysis Focus\n",
        "\n",
        "For this part of the lab, we'll focus on the **5 mean features** to keep our analysis manageable:\n",
        "- `radius_mean`, `texture_mean`, `perimeter_mean`, `area_mean`, `smoothness_mean`\n",
        "\n",
        "These provide a representative sample of size, texture, and shape characteristics that are clinically relevant for distinguishing malignant from benign tumors.\n",
        "\n",
        "**Business Context**: In medical diagnosis, the costs of different errors are dramatically different. Missing a malignant tumor (false negative) can be life-threatening, while incorrectly flagging a benign tumor as malignant (false positive) leads to unnecessary stress and additional testing costs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {
        "id": "cell-10"
      },
      "source": [
        "### Exercise 2.1: Data Loading and Exploration\n",
        "\n",
        "**Your Task**: Load the breast cancer dataset and perform initial exploratory analysis.\n",
        "\n",
        "**Instructions**:\n",
        "1. Load the dataset from the provided URL\n",
        "2. Examine the dataset structure (shape, columns, first few rows)\n",
        "3. Calculate the baseline ratio of malignant vs benign diagnoses\n",
        "4. Check for any missing values in the dataset\n",
        "\n",
        "**Questions to Answer**:\n",
        "- How many observations and features does the dataset contain?\n",
        "- What percentage of cases are malignant vs benign?\n",
        "- Are there any missing values that need to be handled?\n",
        "\n",
        "Write your code below to answer these questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cell-11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-11",
        "outputId": "2041efd8-5a70-49c2-969f-3785cd580003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Breast Cancer Wisconsin dataset loaded successfully!\n",
            "\n",
            "Dataset Structure:\n",
            "Shape: (569, 31)\n",
            "\n",
            "Columns: ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
            "\n",
            "First few rows:\n",
            "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0         M        17.99         10.38          122.80     1001.0   \n",
            "1         M        20.57         17.77          132.90     1326.0   \n",
            "2         M        19.69         21.25          130.00     1203.0   \n",
            "3         M        11.42         20.38           77.58      386.1   \n",
            "4         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0         0.2419  ...         25.38          17.33           184.60   \n",
            "1         0.1812  ...         24.99          23.41           158.80   \n",
            "2         0.2069  ...         23.57          25.53           152.50   \n",
            "3         0.2597  ...         14.91          26.50            98.87   \n",
            "4         0.1809  ...         22.54          16.67           152.20   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "📊 Baseline Analysis:\n",
            "Malignant cases: 212 (37.3%)\n",
            "Benign cases: 357 (62.7%)\n",
            "\n",
            "Missing Values:\n",
            "diagnosis                  0\n",
            "radius_mean                0\n",
            "texture_mean               0\n",
            "perimeter_mean             0\n",
            "area_mean                  0\n",
            "smoothness_mean            0\n",
            "compactness_mean           0\n",
            "concavity_mean             0\n",
            "concave points_mean        0\n",
            "symmetry_mean              0\n",
            "fractal_dimension_mean     0\n",
            "radius_se                  0\n",
            "texture_se                 0\n",
            "perimeter_se               0\n",
            "area_se                    0\n",
            "smoothness_se              0\n",
            "compactness_se             0\n",
            "concavity_se               0\n",
            "concave points_se          0\n",
            "symmetry_se                0\n",
            "fractal_dimension_se       0\n",
            "radius_worst               0\n",
            "texture_worst              0\n",
            "perimeter_worst            0\n",
            "area_worst                 0\n",
            "smoothness_worst           0\n",
            "compactness_worst          0\n",
            "concavity_worst            0\n",
            "concave points_worst       0\n",
            "symmetry_worst             0\n",
            "fractal_dimension_worst    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2.1: Your code here\n",
        "\n",
        "# URL for the breast cancer dataset\n",
        "url = \"https://raw.githubusercontent.com/bradleyboehmke/uc-bana-4080/refs/heads/main/data/breast_cancer.csv\"\n",
        "\n",
        "# Task 1: Load the dataset (PROVIDED)\n",
        "cancer_data = pd.read_csv(url)\n",
        "print(\"✅ Breast Cancer Wisconsin dataset loaded successfully!\")\n",
        "\n",
        "# Task 2: Examine dataset structure (shape, columns, first few rows)\n",
        "# Write your code here\n",
        "print(\"\\nDataset Structure:\")\n",
        "print(f\"Shape: {cancer_data.shape}\")\n",
        "print(f\"\\nColumns: {cancer_data.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(cancer_data.head())\n",
        "\n",
        "# Task 3: Calculate baseline ratio of malignant vs benign diagnoses\n",
        "# Write your code here\n",
        "malignant_count = (cancer_data['diagnosis'] == 'M').sum()\n",
        "benign_count = (cancer_data['diagnosis'] == 'B').sum()\n",
        "total_count = len(cancer_data)\n",
        "\n",
        "malignant_ratio = malignant_count / total_count\n",
        "benign_ratio = benign_count / total_count\n",
        "\n",
        "print(f\"\\n📊 Baseline Analysis:\")\n",
        "print(f\"Malignant cases: {malignant_count} ({malignant_ratio:.1%})\")\n",
        "print(f\"Benign cases: {benign_count} ({benign_ratio:.1%})\")\n",
        "\n",
        "\n",
        "# Task 4: Check for missing values\n",
        "# Write your code here\n",
        "print(\"\\nMissing Values:\")\n",
        "print(cancer_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cell-12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-12",
        "outputId": "254b9828-1aef-4cb7-b53c-f53223236919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TA will provide solution during lab walkthrough\n"
          ]
        }
      ],
      "source": [
        "# Solution will be provided by TA during lab\n",
        "\n",
        "# This cell will contain the solution code that the TA will walk through\n",
        "# Students should attempt the exercise above before seeing the solution\n",
        "\n",
        "print(\"✅ TA will provide solution during lab walkthrough\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {
        "id": "cell-13"
      },
      "source": [
        "### Exercise 2.2: Data Preparation and Modeling (Using Mean Features Only)\n",
        "\n",
        "**Your Task**: Prepare the breast cancer data for logistic regression analysis using only the `_mean` features.\n",
        "\n",
        "**Background**: For this exercise, we'll focus on a subset of features to keep the analysis manageable. You'll work with the 10 `_mean` features, which represent the average measurements across all cells in each sample.\n",
        "\n",
        "**Instructions**:\n",
        "1. Create a binary target variable (0=Benign, 1=Malignant) from the diagnosis column\n",
        "2. Select only the features ending with `_mean` for your feature matrix\n",
        "3. Split the data into training and test sets (70-30 split)\n",
        "4. Fit a logistic regression model and examine the coefficients\n",
        "5. Make predictions on the test set\n",
        "\n",
        "**Important**: Use `RANDOM_STATE` variable (defined at the beginning) for consistent results across all students.\n",
        "\n",
        "**Questions to Answer**:\n",
        "- How many `_mean` features are available in the dataset?\n",
        "- What are the training and test set sizes after the split?\n",
        "- Which `_mean` features have positive vs negative coefficients?\n",
        "- What do the coefficient signs suggest about malignancy risk?\n",
        "\n",
        "Write your code below to complete these tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cell-14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-14",
        "outputId": "7fb5a714-0aba-473b-b753-348d685900e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Selected 10 mean features:\n",
            "Features: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
            "\n",
            "Data Split Results:\n",
            "Training set shape: (398, 10)\n",
            "Test set shape: (171, 10)\n",
            "Training target shape: (398,)\n",
            "Test target shape: (171,)\n",
            "🔍 Model Coefficients (Mean Features):\n",
            "Intercept: -1.795188\n",
            "radius_mean: -3.654495\n",
            "texture_mean: 0.179197\n",
            "perimeter_mean: 0.384172\n",
            "area_mean: 0.021616\n",
            "smoothness_mean: 0.577701\n",
            "compactness_mean: 1.068090\n",
            "concavity_mean: 1.738485\n",
            "concave points_mean: 1.035501\n",
            "symmetry_mean: 0.741410\n",
            "fractal_dimension_mean: 0.121101\n",
            "\n",
            "💡 Interpretation:\n",
            "Features with positive coefficients (e.g., radius_mean, perimeter_mean, area_mean) are associated with an increased likelihood of malignancy.\n",
            "Features with negative coefficients (e.g., fractal_dimension_mean) are associated with a decreased likelihood of malignancy.\n",
            "✅ Predictions on test set complete.\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2.2: Your code here\n",
        "# Assume the cancer_data DataFrame is available from Exercise 2.1\n",
        "\n",
        "# Task 1: Create binary target variable (0=Benign, 1=Malignant)\n",
        "# Write your code here\n",
        "cancer_data['diagnosis_binary'] = (cancer_data['diagnosis'] == 'M').astype(int)\n",
        "y_cancer = cancer_data['diagnosis_binary']\n",
        "\n",
        "\n",
        "# Task 2: Select only the features ending with '_mean' (PROVIDED)\n",
        "mean_features = [col for col in cancer_data.columns if col.endswith('_mean')]\n",
        "X_cancer_mean = cancer_data[mean_features]\n",
        "print(f\"✅ Selected {len(mean_features)} mean features:\")\n",
        "print(f\"Features: {mean_features}\")\n",
        "\n",
        "# Task 3: Split data into training and test sets (70-30 split using RANDOM_STATE)\n",
        "# Write your code here\n",
        "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
        "    X_cancer_mean, y_cancer, test_size=0.3, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"\\nData Split Results:\")\n",
        "print(f\"Training set shape: {X_train_cancer.shape}\")\n",
        "print(f\"Test set shape: {X_test_cancer.shape}\")\n",
        "print(f\"Training target shape: {y_train_cancer.shape}\")\n",
        "print(f\"Test target shape: {y_test_cancer.shape}\")\n",
        "\n",
        "# Task 4: Fit logistic regression model and examine coefficients\n",
        "\n",
        "# Fit logistic regression model\n",
        "model_mean_features = LogisticRegression(random_state=RANDOM_STATE)\n",
        "model_mean_features.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "# Examine model coefficients\n",
        "print(\"🔍 Model Coefficients (Mean Features):\")\n",
        "print(f\"Intercept: {model_mean_features.intercept_[0]:.6f}\")\n",
        "for feature, coef in zip(X_cancer_mean.columns, model_mean_features.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.6f}\")\n",
        "\n",
        "print(f\"\\n💡 Interpretation:\")\n",
        "print(f\"Features with positive coefficients (e.g., radius_mean, perimeter_mean, area_mean) are associated with an increased likelihood of malignancy.\")\n",
        "print(f\"Features with negative coefficients (e.g., fractal_dimension_mean) are associated with a decreased likelihood of malignancy.\")\n",
        "\n",
        "# Task 5: Make predictions on test set\n",
        "\n",
        "# Make binary predictions\n",
        "y_pred_cancer = model_mean_features.predict(X_test_cancer)\n",
        "\n",
        "# Make probability predictions (for ROC-AUC later)\n",
        "y_pred_proba_cancer = model_mean_features.predict_proba(X_test_cancer)[:, 1]\n",
        "\n",
        "print(\"✅ Predictions on test set complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {
        "id": "cell-15"
      },
      "outputs": [],
      "source": [
        "# Solution will be provided by TA during lab\n",
        "\n",
        "# This cell will contain the solution code that the TA will walk through\n",
        "# Students should attempt Exercise 2.2 above before seeing the solution\n",
        "\n",
        "print(\"✅ TA will provide solution during lab walkthrough\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {
        "id": "cell-16"
      },
      "source": [
        "### Exercise 2.3: Model Evaluation\n",
        "\n",
        "**Your Task**: Evaluate the performance of your logistic regression model using multiple classification metrics.\n",
        "\n",
        "**Instructions**:\n",
        "1. Calculate accuracy, precision, recall, and F1-score on the test set\n",
        "2. Calculate the ROC-AUC score\n",
        "3. Create and interpret the confusion matrix\n",
        "4. Discuss which metrics are most important for medical diagnosis\n",
        "\n",
        "**Questions to Answer**:\n",
        "- What is the model's performance across different metrics?\n",
        "- In the context of cancer diagnosis, which type of error (false positive vs false negative) is more concerning?\n",
        "- How does this model's performance compare to the baseline?\n",
        "\n",
        "Write your code below to evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "cell-17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-17",
        "outputId": "c15a1edb-4a76-4908-f055-cc13a0181151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Model Performance Metrics (Mean Features):\n",
            "Accuracy:  93.6%\n",
            "Precision: 91.9%\n",
            "Recall:    90.5%\n",
            "F1-Score:  91.2%\n",
            "ROC-AUC:   0.991\n",
            "\n",
            "🔍 Confusion Matrix (Mean Features):\n",
            "[[103,   5]]\n",
            "[[  6,  57]]\n",
            "\n",
            "This shows: TN=103, FP=5, FN=6, TP=57\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2.3: Your code here\n",
        "# Assume you have y_test and predictions available from Exercise 2.2\n",
        "\n",
        "# Task 1: Calculate classification metrics\n",
        "# Write your code here for accuracy, precision, recall, F1-score\n",
        "accuracy_cancer = accuracy_score(y_test_cancer, y_pred_cancer)\n",
        "precision_cancer = precision_score(y_test_cancer, y_pred_cancer)\n",
        "recall_cancer = recall_score(y_test_cancer, y_pred_cancer)\n",
        "f1_cancer = f1_score(y_test_cancer, y_pred_cancer)\n",
        "\n",
        "print(\"📈 Model Performance Metrics (Mean Features):\")\n",
        "print(f\"Accuracy:  {accuracy_cancer:.1%}\")\n",
        "print(f\"Precision: {precision_cancer:.1%}\")\n",
        "print(f\"Recall:    {recall_cancer:.1%}\")\n",
        "print(f\"F1-Score:  {f1_cancer:.1%}\")\n",
        "\n",
        "\n",
        "# Task 2: Calculate ROC-AUC score\n",
        "# Write your code here\n",
        "auc_cancer = roc_auc_score(y_test_cancer, y_pred_proba_cancer)\n",
        "print(f\"ROC-AUC:   {auc_cancer:.3f}\")\n",
        "\n",
        "# Task 3: Create and display confusion matrix\n",
        "# Write your code here\n",
        "cm_cancer = confusion_matrix(y_test_cancer, y_pred_cancer)\n",
        "print(f\"\\n🔍 Confusion Matrix (Mean Features):\")\n",
        "print(f\"[[{cm_cancer[0,0]:3d}, {cm_cancer[0,1]:3d}]]\")\n",
        "print(f\"[[{cm_cancer[1,0]:3d}, {cm_cancer[1,1]:3d}]]\")\n",
        "print(f\"\\nThis shows: TN={cm_cancer[0,0]}, FP={cm_cancer[0,1]}, FN={cm_cancer[1,0]}, TP={cm_cancer[1,1]}\")\n",
        "\n",
        "# Task 4: Interpret results in medical context\n",
        "# Write your analysis as comments:\n",
        "# - Which metric is most important for cancer diagnosis and why?\n",
        "# The most important metric in cancer diagnosis is recall (sensitivity) because\n",
        "# recall measures the proportion of actual positive cases that are correctly\n",
        "# identified by the model. A high recall mean the model is very good at catching\n",
        "# malignant tumors.\n",
        "\n",
        "# - What are the implications of false positives vs false negatives?\n",
        "# False positives create a lot of patient anxiety when it is not necessary. It\n",
        "# also leads to unnecessary follow-up tests and procedures, which costs time,\n",
        "# money, and energy.\n",
        "# False negatives lead to delayed and missed treaments, which can increase the\n",
        "# severity and the likelihood of death or serious complications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {
        "id": "cell-18"
      },
      "source": [
        "## Part 3 — Independent Analysis: Full Feature Model (35 minutes)\n",
        "\n",
        "Now that you've worked through the logistic regression process with the `_mean` features, it's time to apply the same workflow using **all available features** in the dataset. This will give you experience with higher-dimensional data and allow you to compare model performance.\n",
        "\n",
        "### 🎯 Your Challenge\n",
        "\n",
        "Repeat the complete logistic regression analysis from Part 2, but this time use **all 30 quantitative features** (mean, standard error, and worst values for each of the 10 characteristics). This represents a more realistic scenario where you have access to the full feature set.\n",
        "\n",
        "**Key Differences from Part 2**:\n",
        "- Use ALL features except the `diagnosis` column (30 features total)\n",
        "- Follow the same workflow: data prep → modeling → evaluation\n",
        "- Compare results with your Part 2 model using only `_mean` features\n",
        "- Work independently to write all the code\n",
        "\n",
        "### 📋 Workflow Steps to Complete\n",
        "\n",
        "1. **Data Preparation**\n",
        "   - Create binary target variable\n",
        "   - Select all quantitative features (exclude 'diagnosis')\n",
        "   - Split into 70-30 train/test (use `RANDOM_STATE` for consistency)\n",
        "\n",
        "2. **Model Training**\n",
        "   - Fit logistic regression model\n",
        "   - Examine and interpret coefficients\n",
        "   - Make predictions on test set\n",
        "\n",
        "3. **Model Evaluation**\n",
        "   - Calculate all classification metrics\n",
        "   - Create confusion matrix\n",
        "   - Compare performance to Part 2 model\n",
        "\n",
        "4. **Analysis and Comparison**\n",
        "   - Which model performs better and why?\n",
        "   - Does using more features always improve performance?\n",
        "   - Which features seem most important for prediction?\n",
        "\n",
        "**Important Notes**:\n",
        "- Work independently on this section\n",
        "- Use the same `RANDOM_STATE` for consistent results\n",
        "- Feel free to ask conceptual questions, but write your own code\n",
        "- We'll review solutions together at the end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {
        "id": "cell-19"
      },
      "source": [
        "### Step 1: Data Preparation with All Features\n",
        "\n",
        "**Task**: Prepare the data using all 30 quantitative features instead of just the `_mean` features.\n",
        "\n",
        "Write your code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cell-20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-20",
        "outputId": "fe90ddc6-d297-4d7a-a029-3f6df7648af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Split Results (Full Features):\n",
            "Training set shape: (398, 30)\n",
            "Test set shape: (171, 30)\n",
            "Training target shape: (398,)\n",
            "Test target shape: (171,)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Data Preparation with All Features\n",
        "# Assume cancer_data DataFrame is available from Part 2\n",
        "\n",
        "# Create binary target variable (if not already done)\n",
        "# Write your code here\n",
        "cancer_data['diagnosis_binary'] = (cancer_data['diagnosis'] == 'M').astype(int)\n",
        "y_cancer_full = cancer_data['diagnosis_binary']\n",
        "\n",
        "\n",
        "# Select ALL quantitative features (exclude 'diagnosis' column)\n",
        "# Hint: You can use cancer_data.drop() or select columns that aren't 'diagnosis'\n",
        "# Write your code here\n",
        "X_cancer_full = cancer_data.drop(['diagnosis', 'diagnosis_binary'], axis=1)\n",
        "\n",
        "# Split into training and test sets (70-30 split using RANDOM_STATE)\n",
        "# Write your code here\n",
        "X_train_cancer_full, X_test_cancer_full, y_train_cancer_full, y_test_cancer_full = train_test_split(\n",
        "    X_cancer_full, y_cancer_full, test_size=0.3, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Verify your data preparation\n",
        "# Write code to check shapes and feature count\n",
        "print(\"\\nData Split Results (Full Features):\")\n",
        "print(f\"Training set shape: {X_train_cancer_full.shape}\")\n",
        "print(f\"Test set shape: {X_test_cancer_full.shape}\")\n",
        "print(f\"Training target shape: {y_train_cancer_full.shape}\")\n",
        "print(f\"Test target shape: {y_test_cancer_full.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {
        "id": "cell-21"
      },
      "source": [
        "### Step 2: Model Training with All Features\n",
        "\n",
        "**Task**: Train a logistic regression model using all 30 features and examine the results.\n",
        "\n",
        "Write your code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cell-22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-22",
        "outputId": "eb226dc4-9aa2-4aa1-ff64-a032cc09ab68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Model Coefficients (Full Features):\n",
            "Intercept: -1.392738\n",
            "radius_mean: -2.312700\n",
            "texture_mean: -0.154609\n",
            "perimeter_mean: 0.158037\n",
            "area_mean: 0.003074\n",
            "smoothness_mean: 0.150181\n",
            "compactness_mean: 0.431378\n",
            "concavity_mean: 0.721410\n",
            "concave points_mean: 0.402336\n",
            "symmetry_mean: 0.235475\n",
            "fractal_dimension_mean: 0.031494\n",
            "radius_se: 0.114353\n",
            "texture_se: -1.292614\n",
            "perimeter_se: 0.062642\n",
            "area_se: 0.093660\n",
            "smoothness_se: 0.018080\n",
            "compactness_se: 0.008153\n",
            "concavity_se: 0.056885\n",
            "concave points_se: 0.047538\n",
            "symmetry_se: 0.057239\n",
            "fractal_dimension_se: -0.001039\n",
            "radius_worst: -0.990085\n",
            "texture_worst: 0.389544\n",
            "perimeter_worst: 0.048218\n",
            "area_worst: 0.022069\n",
            "smoothness_worst: 0.278742\n",
            "compactness_worst: 1.131140\n",
            "concavity_worst: 1.671545\n",
            "concave points_worst: 0.696230\n",
            "symmetry_worst: 0.844460\n",
            "fractal_dimension_worst: 0.111672\n",
            "\n",
            "✅ Predictions on test set (Full Features) complete.\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Model Training with All Features\n",
        "\n",
        "# Fit logistic regression model using RANDOM_STATE\n",
        "# Write your code here\n",
        "model_full_features = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "model_full_features.fit(X_train_cancer_full, y_train_cancer_full)\n",
        "\n",
        "# Examine model coefficients\n",
        "# Write your code here to display intercept and feature coefficients\n",
        "print(\"\\n🔍 Model Coefficients (Full Features):\")\n",
        "print(f\"Intercept: {model_full_features.intercept_[0]:.6f}\")\n",
        "for feature, coef in zip(X_cancer_full.columns, model_full_features.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.6f}\")\n",
        "\n",
        "\n",
        "# Make predictions on test set (both binary and probability predictions)\n",
        "# Write your code here\n",
        "y_pred_cancer_full = model_full_features.predict(X_test_cancer_full)\n",
        "y_pred_proba_cancer_full = model_full_features.predict_proba(X_test_cancer_full)[:, 1]\n",
        "\n",
        "print(\"\\n✅ Predictions on test set (Full Features) complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {
        "id": "cell-23"
      },
      "source": [
        "### Step 3: Model Evaluation and Comparison\n",
        "\n",
        "**Task**: Evaluate your full-feature model and compare it with the `_mean`-only model from Part 2.\n",
        "\n",
        "Write your code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cell-24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-24",
        "outputId": "1ed8cc39-fd36-452c-85bf-cdcd2965cda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Model Performance Metrics (Full Features):\n",
            "Accuracy:  96.5%\n",
            "Precision: 96.7%\n",
            "Recall:    93.7%\n",
            "F1-Score:  95.2%\n",
            "ROC-AUC:   0.998\n",
            "\n",
            "🔍 Confusion Matrix (Full Features):\n",
            "[[106,   2]]\n",
            "[[  4,  59]]\n",
            "\n",
            "This shows: TN=106, FP=2, FN=4, TP=59\n",
            "\n",
            "📊 Model Comparison:\n",
            "---------------------------------------------\n",
            "Metric     | Mean Features | Full Features\n",
            "---------------------------------------------\n",
            "Accuracy   | 93.6%         | 96.5%\n",
            "Precision  | 91.9%         | 96.7%\n",
            "Recall     | 90.5%         | 93.7%\n",
            "F1-Score   | 91.2%         | 95.2%\n",
            "ROC-AUC    | 0.991         | 0.998\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Model Evaluation and Comparison\n",
        "\n",
        "# Calculate all classification metrics for the full-feature model\n",
        "# Write your code here for accuracy, precision, recall, F1-score, ROC-AUC\n",
        "accuracy_cancer_full = accuracy_score(y_test_cancer_full, y_pred_cancer_full)\n",
        "precision_cancer_full = precision_score(y_test_cancer_full, y_pred_cancer_full)\n",
        "recall_cancer_full = recall_score(y_test_cancer_full, y_pred_cancer_full)\n",
        "f1_cancer_full = f1_score(y_test_cancer_full, y_pred_cancer_full)\n",
        "auc_cancer_full = roc_auc_score(y_test_cancer_full, y_pred_proba_cancer_full)\n",
        "\n",
        "print(\"📈 Model Performance Metrics (Full Features):\")\n",
        "print(f\"Accuracy:  {accuracy_cancer_full:.1%}\")\n",
        "print(f\"Precision: {precision_cancer_full:.1%}\")\n",
        "print(f\"Recall:    {recall_cancer_full:.1%}\")\n",
        "print(f\"F1-Score:  {f1_cancer_full:.1%}\")\n",
        "print(f\"ROC-AUC:   {auc_cancer_full:.3f}\")\n",
        "\n",
        "# Create and display confusion matrix\n",
        "# Write your code here\n",
        "cm_cancer_full = confusion_matrix(y_test_cancer_full, y_pred_cancer_full)\n",
        "print(f\"\\n🔍 Confusion Matrix (Full Features):\")\n",
        "print(f\"[[{cm_cancer_full[0,0]:3d}, {cm_cancer_full[0,1]:3d}]]\")\n",
        "print(f\"[[{cm_cancer_full[1,0]:3d}, {cm_cancer_full[1,1]:3d}]]\")\n",
        "print(f\"\\nThis shows: TN={cm_cancer_full[0,0]}, FP={cm_cancer_full[0,1]}, FN={cm_cancer_full[1,0]}, TP={cm_cancer_full[1,1]}\")\n",
        "\n",
        "\n",
        "# Compare with Part 2 results\n",
        "# Write code to display metrics from both models side by side\n",
        "print(\"\\n📊 Model Comparison:\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"Metric     | Mean Features | Full Features\")\n",
        "print(\"---------------------------------------------\")\n",
        "print(f\"Accuracy   | {accuracy_cancer:.1%}         | {accuracy_cancer_full:.1%}\")\n",
        "print(f\"Precision  | {precision_cancer:.1%}         | {precision_cancer_full:.1%}\")\n",
        "print(f\"Recall     | {recall_cancer:.1%}         | {recall_cancer_full:.1%}\")\n",
        "print(f\"F1-Score   | {f1_cancer:.1%}         | {f1_cancer_full:.1%}\")\n",
        "print(f\"ROC-AUC    | {auc_cancer:.3f}         | {auc_cancer_full:.3f}\")\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "\n",
        "# Analysis questions (answer in comments):\n",
        "# 1. Which model performs better overall?\n",
        "# The Full Features Model performs better across almost all metrics: accuracy,\n",
        "# precision, recall, etc.\n",
        "\n",
        "# 2. Does using more features improve performance? Why or why not?\n",
        "# Yes, using more features improves performance because they provide addtional\n",
        "# relevant information that helps reduce errors\n",
        "\n",
        "# 3. Are there any trade-offs between the two models?\n",
        "# While the full-feature model is mostly better, there is a trade-off in terms\n",
        "# of its complexity and interpretability. This model has a lot more features,\n",
        "# which can make understanding it more difficult.\n",
        "\n",
        "# 4. In a real medical setting, which model would you prefer and why?\n",
        "# I would much prefer the Full Feature Model, as accuracy and minimalization of\n",
        "# errors is extremely important. The higher accuracy in diagnoses is always\n",
        "# the top priority. Much more important than complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01564e5",
      "metadata": {
        "id": "c01564e5"
      },
      "source": [
        "### Step 4: Feature Importance Analysis\n",
        "\n",
        "**Understanding Feature Importance**:\n",
        "\n",
        "While we haven't formally covered feature importance methods yet, we can gain insights about which features matter most in our logistic regression model by examining the **magnitude (absolute value) of the coefficients**.\n",
        "\n",
        "**Key Concept**: In logistic regression, features with **larger absolute coefficient values** have more influence on the prediction. Here's why:\n",
        "\n",
        "- **Large positive coefficient**: Strong evidence that higher values of this feature increase the likelihood of malignancy\n",
        "- **Large negative coefficient**: Strong evidence that higher values of this feature decrease the likelihood of malignancy  \n",
        "- **Small coefficient (near zero)**: This feature has minimal impact on the prediction\n",
        "\n",
        "**For this analysis**, we'll assume that features with the largest absolute coefficient values represent the most influential features in our model. This gives us insight into which measurements are most important for distinguishing between malignant and benign tumors.\n",
        "\n",
        "**Your Task**: Identify which features have the strongest influence on predictions and interpret what this means clinically.\n",
        "\n",
        "Write your code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "cell-26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-26",
        "outputId": "a9514d9c-aff9-41a4-c497-fe526b6cf10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ Most Influential Features (by absolute coefficient magnitude):\n",
            "radius_mean             2.312700\n",
            "concavity_worst         1.671545\n",
            "texture_se              1.292614\n",
            "compactness_worst       1.131140\n",
            "radius_worst            0.990085\n",
            "symmetry_worst          0.844460\n",
            "concavity_mean          0.721410\n",
            "concave points_worst    0.696230\n",
            "compactness_mean        0.431378\n",
            "concave points_mean     0.402336\n",
            "dtype: float64\n",
            "\n",
            "Features with largest positive coefficients (increase malignancy risk):\n",
            "concavity_worst         1.671545\n",
            "compactness_worst       1.131140\n",
            "symmetry_worst          0.844460\n",
            "concavity_mean          0.721410\n",
            "concave points_worst    0.696230\n",
            "dtype: float64\n",
            "\n",
            "Features with largest negative coefficients (decrease malignancy risk):\n",
            "radius_mean            -2.312700\n",
            "texture_se             -1.292614\n",
            "radius_worst           -0.990085\n",
            "texture_mean           -0.154609\n",
            "fractal_dimension_se   -0.001039\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# (Optional) Step 4: Feature Importance Analysis\n",
        "\n",
        "# Find features with largest positive and negative coefficients\n",
        "# Write your code here to identify most influential features\n",
        "coefficients = pd.Series(model_full_features.coef_[0], index=X_cancer_full.columns)\n",
        "sorted_coefficients = coefficients.abs().sort_values(ascending=False)\n",
        "\n",
        "print(\"✨ Most Influential Features (by absolute coefficient magnitude):\")\n",
        "print(sorted_coefficients.head(10)) # Display top 10 most influential features\n",
        "\n",
        "print(\"\\nFeatures with largest positive coefficients (increase malignancy risk):\")\n",
        "print(coefficients.sort_values(ascending=False).head(5)) # Display top 5 positive coefficients\n",
        "\n",
        "print(\"\\nFeatures with largest negative coefficients (decrease malignancy risk):\")\n",
        "print(coefficients.sort_values(ascending=True).head(5)) # Display top 5 negative coefficients\n",
        "\n",
        "\n",
        "# Create a visualization of feature importance (optional)\n",
        "# You could create a bar plot or horizontal bar plot of coefficients\n",
        "\n",
        "\n",
        "# Interpretation questions (answer in comments):\n",
        "# 1. Which features have the strongest positive coefficients (increase malignancy risk)?\n",
        "# 2. Which features have the strongest negative coefficients (decrease malignancy risk)?\n",
        "# 3. Do these results make biological/medical sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-29",
      "metadata": {
        "id": "cell-29"
      },
      "source": [
        "### Step 5 — Business Cost Analysis\n",
        "\n",
        "**Question**: Using your full-feature model from Part 3, calculate the business cost of classification errors using the same cost structure from the Default dataset example:\n",
        "\n",
        "- False Negative (missed cancer): $50,000 per case\n",
        "- False Positive (unnecessary alarm): $2,000 per case\n",
        "\n",
        "Compare this with the cost if you used the Part 2 model. Which model is more cost-effective?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "cell-30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-30",
        "outputId": "35c85f03-369d-4ad7-9d67-5b7ef0c448f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business Cost (Full Features Model):\n",
            "  False Negatives (missed cancers): 4 * $50,000 = $200,000\n",
            "  False Positives (unnecessary alarms): 2 * $2,000 = $4,000\n",
            "  Total Estimated Cost: $204,000\n",
            "\n",
            "Business Cost (Mean Features Model):\n",
            "  False Negatives (missed cancers): 6 * $50,000 = $300,000\n",
            "  False Positives (unnecessary alarms): 5 * $2,000 = $10,000\n",
            "  Total Estimated Cost: $310,000\n"
          ]
        }
      ],
      "source": [
        "# Challenge 2: Business Cost Analysis\n",
        "\n",
        "# Calculate costs for full-feature model (Part 3)\n",
        "# Write your code here\n",
        "# Assuming cm_cancer_full is available from Step 3\n",
        "\n",
        "false_negative_cost = 50000  # Cost of a missed cancer\n",
        "false_positive_cost = 2000   # Cost of an unnecessary alarm\n",
        "\n",
        "fn_full = cm_cancer_full[1, 0]\n",
        "fp_full = cm_cancer_full[0, 1]\n",
        "\n",
        "total_cost_full = (fn_full * false_negative_cost) + (fp_full * false_positive_cost)\n",
        "\n",
        "print(f\"Business Cost (Full Features Model):\")\n",
        "print(f\"  False Negatives (missed cancers): {fn_full} * ${false_negative_cost:,} = ${fn_full * false_negative_cost:,}\")\n",
        "print(f\"  False Positives (unnecessary alarms): {fp_full} * ${false_positive_cost:,} = ${fp_full * false_positive_cost:,}\")\n",
        "print(f\"  Total Estimated Cost: ${total_cost_full:,}\")\n",
        "\n",
        "\n",
        "# Calculate costs for mean-only model (Part 2)\n",
        "# Write your code here\n",
        "# Assuming cm_cancer is available from Exercise 2.3\n",
        "\n",
        "fn_mean = cm_cancer[1, 0]\n",
        "fp_mean = cm_cancer[0, 1]\n",
        "\n",
        "total_cost_mean = (fn_mean * false_negative_cost) + (fp_mean * false_positive_cost)\n",
        "\n",
        "print(f\"\\nBusiness Cost (Mean Features Model):\")\n",
        "print(f\"  False Negatives (missed cancers): {fn_mean} * ${false_negative_cost:,} = ${fn_mean * false_negative_cost:,}\")\n",
        "print(f\"  False Positives (unnecessary alarms): {fp_mean} * ${false_positive_cost:,} = ${fp_mean * false_positive_cost:,}\")\n",
        "print(f\"  Total Estimated Cost: ${total_cost_mean:,}\")\n",
        "\n",
        "\n",
        "# Compare total costs and determine which model is more cost-effective\n",
        "# Write your analysis here\n",
        "# The Full Features Model is more cost-effective because the total estimated\n",
        "# cost is $204,000 as opposed to $310,000 in the Mean Features Model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446bc66c",
      "metadata": {
        "id": "446bc66c"
      },
      "source": [
        "## 🎓 Lab Summary & Wrap-Up\n",
        "\n",
        "### ✅ What You Accomplished Today\n",
        "\n",
        "Congratulations! You've completed a comprehensive analysis of classification models using real medical data. Here's what you mastered:\n",
        "\n",
        "**Part 1 - Review**:\n",
        "- Complete logistic regression workflow with Default dataset\n",
        "- Understanding baseline ratios and model evaluation metrics\n",
        "- Interpreting results in business context (credit risk)\n",
        "\n",
        "**Part 2 - Guided Practice**:\n",
        "- Loading and exploring the Breast Cancer Wisconsin dataset\n",
        "- Data preparation with feature selection (`_mean` features only)\n",
        "- Model training and coefficient interpretation\n",
        "- Classification evaluation in medical context\n",
        "\n",
        "**Part 3 - Independent Analysis**:\n",
        "- Building models with all 30 features\n",
        "- Comparing model performance across different feature sets\n",
        "- Understanding trade-offs between model complexity and performance\n",
        "\n",
        "### 📊 Key Results to Save\n",
        "\n",
        "**🚨 IMPORTANT: Save Your Results for Homework! 🚨**\n",
        "\n",
        "Make sure you have calculated and recorded the following results from your analysis:\n",
        "\n",
        "**From Part 3 (All Features Model)**:\n",
        "- [ ] Training/test set sizes and malignant rates\n",
        "- [ ] Model coefficients for each `_mean` feature\n",
        "- [ ] Classification metrics: accuracy, precision, recall, F1-score, ROC-AUC\n",
        "- [ ] Comparison of performance between mean-only vs full-feature models\n",
        "- [ ] Feature importance insights (which features have strongest coefficients)\n",
        "- [ ] Business cost analysis\n",
        "\n",
        "### 💡 Key Learning Insights\n",
        "\n",
        "**Model Performance**:\n",
        "- How does adding more features affect model performance?\n",
        "- Which evaluation metrics are most important for medical diagnosis?\n",
        "- What are the trade-offs between false positives and false negatives in healthcare?\n",
        "\n",
        "**Business Context**:\n",
        "- Why might a model with high accuracy still be problematic for medical use?\n",
        "- How do business costs influence model selection and threshold decisions?\n",
        "- What factors beyond accuracy should influence model deployment decisions?\n",
        "\n",
        "### 📋 Next Steps & Homework Preparation\n",
        "\n",
        "**This Week's Homework**:\n",
        "Your homework will include specific questions about the models you built today. Make sure you can access:\n",
        "- Your model performance metrics\n",
        "- Specific coefficient values\n",
        "- Predictions for individual observations\n",
        "- Cost analysis results\n",
        "\n",
        "**Study Tips**:\n",
        "- Review Chapter 23 (Logistic Regression) and Chapter 24 (Classification Evaluation)\n",
        "- Practice interpreting confusion matrices and ROC curves\n",
        "- Understand the business implications of different error types\n",
        "\n",
        "### 🔧 Before You Leave\n",
        "\n",
        "**Save Your Work**:\n",
        "1. **Save this notebook** with all your completed code and results\n",
        "2. **Take screenshots** of key results (confusion matrices, metric summaries)\n",
        "3. **Export your notebook** (File → Download as → HTML) as a backup\n",
        "4. **Note key variable names** you used (e.g., model names, prediction arrays)\n",
        "\n",
        "**Double-Check Your Results**:\n",
        "- Did you use `RANDOM_STATE = 42` consistently?\n",
        "- Are your train/test splits 70-30?\n",
        "- Do you have both probability and binary predictions saved?\n",
        "- Are your model performance metrics calculated correctly?\n",
        "\n",
        "---\n",
        "\n",
        "**🎯 Great work today!** You've gained hands-on experience with real-world classification problems and learned to evaluate models from both statistical and business perspectives. These skills are essential for data-driven decision making in healthcare, finance, and many other industries.\n",
        "\n",
        "**Questions?** If you have any questions about your results or need clarification on concepts, reach out before the homework is due. Make sure you understand not just how to calculate the metrics, but what they mean in the context of medical diagnosis."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}